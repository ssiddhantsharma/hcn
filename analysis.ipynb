{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyRosetta Structure Analysis Notebook\n",
    "\n",
    "This notebook analyzes log files from PyRosetta structure validation and creates comprehensive visualizations of the results. It tracks:\n",
    "- Pass/fail statistics for structure validation\n",
    "- Different types of validation failures\n",
    "- Overall success rates and detailed failure analysis\n",
    "\n",
    "## Setup\n",
    "First, let's import required libraries and set up our visualization preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-white')\n",
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Class Definition\n",
    "Now let's define our LogAnalyzer class that will process the log files and create visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class LogAnalyzer:\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the analyzer with failure categories and results storage.\"\"\"\n",
    "        self.failure_categories = {\n",
    "            'terminal_helix': 'Missing Terminal Helix',\n",
    "            'contacts': 'Insufficient Contacts (<2)',\n",
    "            'clashes': 'Helix-Interface Clashes',\n",
    "            'size': 'Structure Too Small',\n",
    "            'chain_split': 'Chain Splitting Error',\n",
    "            'processing': 'Processing Error',\n",
    "            'loop_trim': 'Loop Trimming Failed',\n",
    "            'error': 'Other Errors'\n",
    "        }\n",
    "        self.results = {\n",
    "            'total': 0,\n",
    "            'passed': 0,\n",
    "            'failed': 0,\n",
    "            'failures': defaultdict(int)\n",
    "        }\n",
    "\n",
    "    def parse_log_file(self, log_path):\n",
    "        \"\"\"Parse a single log file and extract detailed statistics.\"\"\"\n",
    "        with open(log_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            \n",
    "        # Count total structures\n",
    "        pdb_matches = re.findall(r\"Analyzing PDB: (.+\\.pdb)\", content)\n",
    "        self.results['total'] += len(pdb_matches)\n",
    "        \n",
    "        # Count passes\n",
    "        passes = re.findall(r\"Result: PASS - All criteria met\", content)\n",
    "        self.results['passed'] += len(passes)\n",
    "        \n",
    "        # Track failures by category\n",
    "        if \"Failed: Missing terminal helix\" in content:\n",
    "            self.results['failures']['terminal_helix'] += 1\n",
    "            \n",
    "        if \"Failed: Insufficient secondary structure contacts\" in content:\n",
    "            self.results['failures']['contacts'] += 1\n",
    "            \n",
    "        if \"Result: FAIL - Found\" in content and \"helix-interface clashes\" in content:\n",
    "            self.results['failures']['clashes'] += 1\n",
    "            \n",
    "        if \"Failed: Structure too small after splitting\" in content:\n",
    "            self.results['failures']['size'] += 1\n",
    "            \n",
    "        if \"Error: Chain splitting failed\" in content:\n",
    "            self.results['failures']['chain_split'] += 1\n",
    "            \n",
    "        if \"Error processing\" in content:\n",
    "            self.results['failures']['processing'] += 1\n",
    "            \n",
    "        if \"Failed: Loop trimming error\" in content:\n",
    "            self.results['failures']['loop_trim'] += 1\n",
    "            \n",
    "        # Update total failures\n",
    "        self.results['failed'] = (self.results['total'] - self.results['passed'])\n",
    "\n",
    "    def analyze_directory(self, base_dir):\n",
    "        \"\"\"Analyze all log files in the given directory structure.\"\"\"\n",
    "        log_pattern = os.path.join(base_dir, \"**\", \"*.log\")\n",
    "        log_files = glob.glob(log_pattern, recursive=True)\n",
    "        \n",
    "        if not log_files:\n",
    "            raise ValueError(f\"No log files found in {base_dir}\")\n",
    "            \n",
    "        print(f\"Found {len(log_files)} log files to analyze\")\n",
    "        for log_file in log_files:\n",
    "            self.parse_log_file(log_file)\n",
    "            \n",
    "        return self.results\n",
    "\n",
    "    def create_visualization(self):\n",
    "        \"\"\"Create comprehensive visualization combining pass/fail and failure reasons.\"\"\"\n",
    "        colors = {\n",
    "            'pass': '#00b894',      # Mint green\n",
    "            'fail': '#ff7675',      # Soft red\n",
    "            'bars': '#74b9ff',      # Light blue\n",
    "            'text': '#2d3436'       # Dark gray\n",
    "        }\n",
    "        \n",
    "        fig = plt.figure(figsize=(12, 16))\n",
    "        gs = fig.add_gridspec(3, 1, height_ratios=[1.2, 0.8, 2])\n",
    "        \n",
    "        # 1. Pass/Fail Donut Chart\n",
    "        ax1 = fig.add_subplot(gs[0])\n",
    "        pass_fail_data = [self.results['passed'], self.results['failed']]\n",
    "        wedges, texts, autotexts = ax1.pie(\n",
    "            pass_fail_data, \n",
    "            labels=['Passed', 'Failed'],\n",
    "            colors=[colors['pass'], colors['fail']], \n",
    "            autopct='%1.1f%%',\n",
    "            pctdistance=0.75,\n",
    "            wedgeprops=dict(width=0.5)\n",
    "        )\n",
    "        plt.setp(autotexts, size=10, weight=\"bold\")\n",
    "        plt.setp(texts, size=12)\n",
    "        ax1.set_title('Structure Validation Results', pad=20, size=14, weight='bold')\n",
    "        \n",
    "        # 2. Summary Statistics\n",
    "        ax2 = fig.add_subplot(gs[1])\n",
    "        ax2.axis('off')\n",
    "        summary_text = (\n",
    "            f\"Total Structures Analyzed: {self.results['total']:,}\\n\"\n",
    "            f\"Passed Validation: {self.results['passed']:,}\\n\"\n",
    "            f\"Failed Validation: {self.results['failed']:,}\\n\"\n",
    "            f\"Overall Pass Rate: {(self.results['passed']/self.results['total']*100):.1f}%\"\n",
    "        )\n",
    "        ax2.text(0.5, 0.5, summary_text, \n",
    "                fontsize=12, linespacing=2, \n",
    "                ha='center', va='center',\n",
    "                color=colors['text'],\n",
    "                fontfamily='sans-serif')\n",
    "        \n",
    "        # 3. Failure Reasons Chart\n",
    "        ax3 = fig.add_subplot(gs[2])\n",
    "        \n",
    "        failure_data = [\n",
    "            {\n",
    "                'reason': display_name,\n",
    "                'count': self.results['failures'][key],\n",
    "                'percentage': (self.results['failures'][key] / self.results['failed'] * 100) \n",
    "                    if self.results['failed'] > 0 else 0\n",
    "            }\n",
    "            for key, display_name in self.failure_categories.items()\n",
    "            if self.results['failures'][key] > 0\n",
    "        ]\n",
    "        \n",
    "        failure_data.sort(key=lambda x: x['count'], reverse=True)\n",
    "        \n",
    "        reasons = [d['reason'] for d in failure_data]\n",
    "        counts = [d['count'] for d in failure_data]\n",
    "        percentages = [d['percentage'] for d in failure_data]\n",
    "        \n",
    "        bars = ax3.barh(reasons, counts, color=[colors['bars']]*len(counts), alpha=0.8)\n",
    "        \n",
    "        ax3.grid(True, axis='x', alpha=0.3)\n",
    "        ax3.set_axisbelow(True)\n",
    "        ax3.spines['top'].set_visible(False)\n",
    "        ax3.spines['right'].set_visible(False)\n",
    "        \n",
    "        for i, (bar, count, percentage) in enumerate(zip(bars, counts, percentages)):\n",
    "            width = bar.get_width()\n",
    "            ax3.text(width, i, f'  {count:,} ({percentage:.1f}%)', \n",
    "                    va='center', fontsize=10, color=colors['text'])\n",
    "        \n",
    "        ax3.set_title('Distribution of Failure Reasons', pad=20, size=14, weight='bold')\n",
    "        ax3.set_xlabel('Number of Structures', size=12, labelpad=10)\n",
    "        ax3.tick_params(axis='both', which='major', labelsize=10)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "        \n",
    "    def save_results(self, output_dir):\n",
    "        \"\"\"Save analysis results and visualization.\"\"\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Save visualization\n",
    "        fig = self.create_visualization()\n",
    "        fig.savefig(os.path.join(output_dir, 'structure_analysis_summary.png'), \n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # Save detailed statistics\n",
    "        stats_df = pd.DataFrame([\n",
    "            {\n",
    "                'Category': name,\n",
    "                'Count': self.results['failures'][key],\n",
    "                'Percentage': (self.results['failures'][key] / self.results['failed'] * 100) \n",
    "                    if self.results['failed'] > 0 else 0\n",
    "            }\n",
    "            for key, name in self.failure_categories.items()\n",
    "        ])\n",
    "        \n",
    "        stats_df.to_csv(os.path.join(output_dir, 'failure_statistics.csv'), index=False)\n",
    "        \n",
    "        # Save summary report\n",
    "        with open(os.path.join(output_dir, 'analysis_summary.txt'), 'w') as f:\n",
    "            f.write(\"PyRosetta Structure Analysis Summary\\n\")\n",
    "            f.write(\"=================================\\n\\n\")\n",
    "            f.write(f\"Total structures analyzed: {self.results['total']:,}\\n\")\n",
    "            f.write(f\"Passed validation: {self.results['passed']:,}\\n\")\n",
    "            f.write(f\"Failed validation: {self.results['failed']:,}\\n\")\n",
    "            if self.results['total'] > 0:\n",
    "                f.write(f\"Pass rate: {(self.results['passed']/self.results['total']*100):.1f}%\\n\")\n",
    "        \n",
    "        print(f\"Results saved to {output_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Log Files\n",
    "Now let's analyze your PyRosetta log files. Just update the input directory path below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set the path to your log files directory\n",
    "input_dir = \"/path/to/pyrosetta_filtered/DLHD_ID/\"\n",
    "\n",
    "# Create analyzer and process logs\n",
    "analyzer = LogAnalyzer()\n",
    "results = analyzer.analyze_directory(input_dir)\n",
    "\n",
    "# Create and display visualization\n",
    "fig = analyzer.create_visualization()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results\n",
    "Let's save our results to files for further analysis or sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set output directory\n",
    "output_dir = \"analysis_results\"\n",
